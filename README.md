# ğŸ¶ vibrato: VIterbi-Based acceleRAted TOkenizer

## Resource preparation

```
$ ./scripts/prepare_ipadic-mecab-2_7_0.sh
$ ./scripts/prepare_unidic-cwj-3_1_0.sh
$ ./scripts/prepare_unidic-mecab-2_1_2.sh
```

## Compiling dictionary

```
$ cargo run --release -p compile -- -r resources_ipadic-mecab-2_7_0 -o system.dic
Compiling the system dictionary...
0.9053542 seconds
Writting the system dictionary...
44.63689613342285 MiB
```

## Tokenize

```
$ echo 'ãƒ´ã‚§ãƒãƒ„ã‚£ã‚¢ã¯ã‚¤ã‚¿ãƒªã‚¢ã«ã‚ã‚Šã¾ã™ã€‚' | cargo run --release -p tokenize -- -i system.dic
Loading the dictionary...
Ready to tokenize :)
ãƒ´ã‚§ãƒãƒ„ã‚£ã‚¢    åè©,ä¸€èˆ¬,*,*,*,*,* (unk)
ã¯      åŠ©è©,ä¿‚åŠ©è©,*,*,*,*,ã¯,ãƒ,ãƒ¯
ã‚¤ã‚¿ãƒªã‚¢        åè©,å›ºæœ‰åè©,åœ°åŸŸ,å›½,*,*,ã‚¤ã‚¿ãƒªã‚¢,ã‚¤ã‚¿ãƒªã‚¢,ã‚¤ã‚¿ãƒªã‚¢
ã«      åŠ©è©,æ ¼åŠ©è©,ä¸€èˆ¬,*,*,*,ã«,ãƒ‹,ãƒ‹
ã‚ã‚Š    å‹•è©,è‡ªç«‹,*,*,äº”æ®µãƒ»ãƒ©è¡Œ,é€£ç”¨å½¢,ã‚ã‚‹,ã‚¢ãƒª,ã‚¢ãƒª
ã¾ã™    åŠ©å‹•è©,*,*,*,ç‰¹æ®Šãƒ»ãƒã‚¹,åŸºæœ¬å½¢,ã¾ã™,ãƒã‚¹,ãƒã‚¹
ã€‚      è¨˜å·,å¥ç‚¹,*,*,*,*,ã€‚,ã€‚,ã€‚
EOS
```

## Benchmark

```
$ cargo run --release -p benchmark -- -i system.dic < benchmark/data/wagahaiwa_nekodearu.txt
[benchmark/src/main.rs:50] n_words = 2462700
Warmup: 0.0813649
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
[benchmark/src/main.rs:50] n_words = 2462700
Number_of_sentences: 2376
Elapsed_seconds_to_tokenize_all_sentences: [0.07661468000000002,0.07816473125,0.08134009]
```
